import asyncio
from playwright.async_api import async_playwright
import re
from utils.spinner import Spinner
from utils.gpt import gpt
from bs4 import BeautifulSoup
from typing import List, Optional

class Crawler:
    def __init__(self, base_url):
        self.base_url = base_url
        self.found_urls = set()

    async def start_crawling(self):
        async with async_playwright() as playwright:
            browser = await playwright.chromium.launch(headless=True)
            page = await browser.new_page()
            await page.goto(self.base_url)
            await page.wait_for_load_state('domcontentloaded')

            # Get the initial HTML content
            html = await page.content()
            crawl_plan = await self.make_plan(html)

            for step in crawl_plan:
                # Execute the steps generated by GPT
                await self.execute_step(page, step)

            await browser.close()

        # Save the found URLs to a file
        with open("crawled_urls.txt", "w") as f:
            for url in self.found_urls:
                f.write(f"{url}\n")
        print("Crawler: Completed URL collection.")

    async def make_plan(self, html: str) -> List[str]:
        """
        Generate a plan to crawl a webpage using GPT based on the HTML content.

        Parameters:
        html (str): HTML content of the current webpage.

        Returns:
        List[str]: Instructions for each navigation step.
        """
        with Spinner("Writing a crawling plan for this website..."):
            prompt = (
                "I am building a web crawler for educational purposes. I have access to a sandbox website, and "
                "I want to know the actions needed to click through and discover additional links on this page. "
                "The webpage's HTML is provided below. Can you generate a series of specific steps to perform "
                "using only mouse clicks and keyboard inputs to help me find more links?\n\n"
                f"```html\n{html}\n```\n\n"
                "Please list each step I should follow."
            )
            
            response = gpt(system_msg="", user_msg=prompt)

        # Parse the GPT response into a list of steps
        lines = response.split('\n')
        plan = [line for line in lines if re.match(r'^\s*\d+\.', line)]
        
        print("Here is the website crawling plan:")
        print('\n'.join(plan))

        return plan

    async def execute_step(self, page, step: str):
        """
        Executes a navigation step generated by GPT.

        Parameters:
        page (playwright.async_api.Page): Playwright page object.
        step (str): A single instruction to execute.
        """
        try:
            # Example step parsing (clicking buttons, links, etc.)
            if "click" in step.lower():
                # Look for instructions on clicking specific elements
                link_match = re.search(r"click on the (.+?) link", step, re.IGNORECASE)
                if link_match:
                    link_text = link_match.group(1)
                    element = await page.query_selector(f"text='{link_text}'")
                    if element:
                        await element.click()
                        print(f"Clicked on link with text: {link_text}")

                # Example for clicking buttons by text
                button_match = re.search(r"click on the (.+?) button", step, re.IGNORECASE)
                if button_match:
                    button_text = button_match.group(1)
                    button = await page.query_selector(f"text='{button_text}'")
                    if button:
                        await button.click()
                        print(f"Clicked on button with text: {button_text}")

            # Capture and store URLs after each interaction
            await self.collect_urls(page)

        except Exception as e:
            print(f"Error executing step '{step}': {e}")

    async def collect_urls(self, page):
        """
        Collects all unique URLs from the current page.

        Parameters:
        page (playwright.async_api.Page): Playwright page object.
        """
        content = await page.content()
        soup = BeautifulSoup(content, 'html.parser')
        for link in soup.find_all("a", href=True):
            url = link['href']
            if url not in self.found_urls:
                full_url = self.make_full_url(url)
                self.found_urls.add(full_url)
                print(f"Found URL: {full_url}")

    def make_full_url(self, url: str) -> str:
        """Convert relative URLs to absolute ones based on the base URL."""
        if url.startswith("http"):
            return url
        return self.base_url.rstrip("/") + "/" + url.lstrip("/")

